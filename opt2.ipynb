{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"E:\\Lip_Wise_GFPGAN\\_testData\\Inputs\\test_trim.mp4\"\n",
    "detector_model_path = r\"E:\\Lip_Wise\\weights\\mp\\blaze_face_short_range.tflite\"\n",
    "landmarker_model_path = r\"E:\\Lip_Wise\\weights\\mp\\face_landmarker.task\"\n",
    "direct = r\"E:\\Lip_Wise\\Result_Analytics\\Cropped_face\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialize mediapipe\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "\n",
    "FaceDetector = mp.tasks.vision.FaceDetector\n",
    "FaceDetectorOptions = mp.tasks.vision.FaceDetectorOptions\n",
    "\n",
    "# Create a face detector instance with the image mode:\n",
    "options_det = FaceDetectorOptions(\n",
    "    base_options=BaseOptions(model_asset_path=detector_model_path),\n",
    "    min_detection_confidence=0.5,\n",
    "    running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "\n",
    "options_lan = FaceLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=landmarker_model_path),\n",
    "    min_face_detection_confidence=0.5,\n",
    "    running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "frame_no = 0\n",
    "no_face_index = []\n",
    "\n",
    "with FaceLandmarker.create_from_options(options_lan) as landmarker,FaceDetector.create_from_options(options_det) as detector:\n",
    "    while video.isOpened() and frame_no < 160:\n",
    "\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB and convert to MediaPipe image\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_frame = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "\n",
    "        # Run face detector and face landmark models in IMAGE mode\n",
    "        result_landmarker = landmarker.detect(mp_frame)\n",
    "        result_detection = detector.detect(mp_frame)\n",
    "        \n",
    "        if len(result_detection.detections) > 0 and len(result_landmarker.face_landmarks) > 0:\n",
    "\n",
    "            # Get landmarks\n",
    "            landmarks_np = np.array([[i.x, i.y] for i in result_landmarker.face_landmarks[0]]).astype(np.float64)\n",
    "\n",
    "            # Get bounding box\n",
    "            # x-coordinates are at even indices and y-coordinates are at odd indices\n",
    "            x_coordinates = landmarks_np[:, 0]\n",
    "            y_coordinates = landmarks_np[:, 1]\n",
    "\n",
    "            # Top-most point has the smallest y-coordinate\n",
    "            y_min = landmarks_np[np.argmin(y_coordinates)]\n",
    "\n",
    "            # Bottom-most point has the largest y-coordinate\n",
    "            y_max = landmarks_np[np.argmax(y_coordinates)]\n",
    "\n",
    "            # Left-most point has the smallest x-coordinate\n",
    "            x_min = landmarks_np[np.argmin(x_coordinates)]\n",
    "\n",
    "            # Right-most point has the largest x-coordinate\n",
    "            x_max = landmarks_np[np.argmax(x_coordinates)]\n",
    "\n",
    "            bbox_np = np.array([[x_min[0], y_min[1]], [x_max[0], y_max[1]]]).astype(np.float64)\n",
    "            bbox_np = bbox_np * [frame.shape[1], frame.shape[0]]\n",
    "\n",
    "            # Crop face\n",
    "            if frame_no%16 == 0:\n",
    "                face = frame[int(bbox_np[0, 1]):int(bbox_np[1, 1]), int(bbox_np[0, 0]):int(bbox_np[1, 0])]\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_RGB2BGR)\n",
    "                face = cv2.resize(face, (96, 96))\n",
    "                # face = cv2.resize(face, (512, 512), interpolation=cv2.INTER_LANCZOS4)\n",
    "                cv2.imwrite(direct + f\"\\\\{frame_no//16}.jpg\", face)\n",
    "    \n",
    "        # Increment frame number\n",
    "        frame_no += 1\n",
    "\n",
    "    # Release video\n",
    "    video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lip-wise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
