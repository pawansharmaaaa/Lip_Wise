{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image\n",
    "\n",
    "app = FaceAnalysis(providers=['CUDAExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = \"/home/thesus/Apps/Assets/video_many_trim.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if ret:\n",
    "    faces = app.get(frame)\n",
    "    rimg = app.draw_on(frame, faces)\n",
    "\n",
    "    plt.imshow(rimg[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = faces[0].normed_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.face_resolver import FaceResolver\n",
    "\n",
    "fr = FaceResolver(input_video, embedding)\n",
    "\n",
    "bboxes = fr.get_bboxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "\n",
    "def process_video(video_file):\n",
    "    video_capture = cv2.VideoCapture(video_file)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    video_capture.release()\n",
    "    return frames\n",
    "\n",
    "def update_frame(frames, frame_index):\n",
    "    return frames[frame_index]\n",
    "\n",
    "def main():\n",
    "    with gr.Blocks() as demo:\n",
    "        video_file = gr.File(label=\"Upload Video\")\n",
    "        frames = gr.State([])\n",
    "        frame_index = gr.Slider(minimum=0, maximum=1, step=1, label=\"Frame Index\", interactive=True)\n",
    "        frame_output = gr.Image(label=\"Frame Preview\")\n",
    "\n",
    "        def load_video(video_file):\n",
    "            frames_list = process_video(video_file.name)\n",
    "            return frames_list, gr.update(maximum=len(frames_list) - 1)\n",
    "\n",
    "        video_file.change(load_video, inputs=[video_file], outputs=[frames, frame_index])\n",
    "        frame_index.change(update_frame, inputs=[frames, frame_index], outputs=[frame_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "import os\n",
    "\n",
    "# Assuming helpers.file_check as fc is correctly configured\n",
    "import helpers.file_check as fc\n",
    "\n",
    "class FaceResolver:\n",
    "    def __init__(self, video_path):\n",
    "        self.video_path = video_path\n",
    "        self.face_detector = FaceAnalysis(providers=['CUDAExecutionProvider'])\n",
    "        self.face_detector.prepare(ctx_id=0, det_size=(640, 640))\n",
    "        \n",
    "        self.selected_embedding = 0\n",
    "        self.faces = []\n",
    "\n",
    "        self.presence_mask = []\n",
    "        self.bboxes = []\n",
    "        self.kps = []\n",
    "\n",
    "    def get_faces(self, frame):\n",
    "        faces = self.face_detector.get(frame)\n",
    "        self.faces = faces\n",
    "    \n",
    "    def get_embedding(self, index, faces):\n",
    "        self.selected_embedding = faces[index].normed_embedding\n",
    "\n",
    "    def _compare_embeddings(self, emb1, emb2, strength = 1.2):\n",
    "        return np.linalg.norm(emb1 - emb2) < strength\n",
    "\n",
    "    def get_preview(self, similarity_strength):\n",
    "        bboxes = []\n",
    "        presence_mask = []\n",
    "        keypoints = []\n",
    "\n",
    "        video = cv2.VideoCapture(self.video_path)\n",
    "\n",
    "        # Metadata\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Writer Object for output video\n",
    "        preview_path = os.path.join(fc.MEDIA_DIR, 'preview.mp4')\n",
    "        writer = cv2.VideoWriter(preview_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "        # Loop through the video\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            faces = self.face_detector.get(frame)\n",
    "            if faces:\n",
    "                present = False\n",
    "                for face in faces:\n",
    "                    bbox = face.bbox.astype(int)\n",
    "                    landmark = face.kps.astype(int)\n",
    "                    embedding = face.normed_embedding\n",
    "                    if self._compare_embeddings(embedding, self.selected_embedding, similarity_strength):\n",
    "                        bboxes.append(bbox)\n",
    "                        keypoints.append(landmark)\n",
    "                        present = True\n",
    "\n",
    "                        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "                        for i in range(5):\n",
    "                            cv2.circle(frame, (landmark[i][0], landmark[i][1]), 1, (0, 0, 255), 2)\n",
    "                presence_mask.append(present)\n",
    "            else:\n",
    "                presence_mask.append(False)\n",
    "            \n",
    "            writer.write(frame)\n",
    "        \n",
    "        self.presence_mask = np.asarray(presence_mask, dtype=bool)\n",
    "        self.bboxes = np.asarray(bboxes)\n",
    "        self.kps = np.asarray(keypoints)\n",
    "        \n",
    "        video.release()\n",
    "        writer.release()\n",
    "        \n",
    "        return preview_path\n",
    "\n",
    "    def save_state(self):\n",
    "        np.save(os.path.join(fc.NPY_FILES_DIR, 'presence_mask.npy'), self.presence_mask)\n",
    "        np.save(os.path.join(fc.NPY_FILES_DIR, 'bboxes.npy'), self.bboxes)\n",
    "        np.save(os.path.join(fc.NPY_FILES_DIR, 'keypoints.npy'), self.kps)\n",
    "\n",
    "def process_video(video_file):\n",
    "    video_capture = cv2.VideoCapture(video_file.name)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    video_capture.release()\n",
    "    return frames\n",
    "\n",
    "def update_frame(frames, frame_index):\n",
    "    return frames[frame_index]\n",
    "\n",
    "def get_faces_in_frame(face_resolver, frame):\n",
    "    face_resolver.get_faces(frame)\n",
    "    faces = face_resolver.faces\n",
    "    face_images = []\n",
    "    for face in faces:\n",
    "        bbox = face.bbox.astype(int)\n",
    "        face_image = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        face_images.append(face_image)\n",
    "    return face_images\n",
    "\n",
    "def generate_preview(face_resolver, face_index, similarity_strength):\n",
    "    face_resolver.get_embedding(face_index, face_resolver.faces)\n",
    "    preview_path = face_resolver.get_preview(similarity_strength)\n",
    "    return preview_path\n",
    "\n",
    "def save_data(face_resolver):\n",
    "    face_resolver.save_state()\n",
    "    return \"Data saved successfully!\"\n",
    "\n",
    "def main():\n",
    "    with gr.Blocks() as demo:\n",
    "        video_file = gr.File(label=\"Upload Video\")\n",
    "        frames = gr.State([])\n",
    "        frame_index = gr.Slider(minimum=0, maximum=1, step=1, label=\"Frame Index\", interactive=True)\n",
    "        frame_output = gr.Image(label=\"Frame Preview\")\n",
    "        face_gallery = gr.Gallery(label=\"Faces in Frame\")\n",
    "        face_index = gr.Number(label=\"Selected Face Index\", value=0)\n",
    "        similarity_strength = gr.Slider(minimum=0.1, maximum=2.0, step=0.1, value=1.2, label=\"Similarity Strength\")\n",
    "        preview_video = gr.Video(label=\"Preview Video\")\n",
    "        preview_button = gr.Button(\"Generate Preview\")\n",
    "        save_button = gr.Button(\"Save Data\")\n",
    "        save_output = gr.Textbox(label=\"Save Status\")\n",
    "\n",
    "        face_resolver = gr.State(None)\n",
    "\n",
    "        def load_video(video_file):\n",
    "            frames_list = process_video(video_file)\n",
    "            frame_index.update(maximum=len(frames_list) - 1)\n",
    "            return frames_list, FaceResolver(video_file.name)\n",
    "\n",
    "        video_file.change(load_video, inputs=[video_file], outputs=[frames, face_resolver])\n",
    "        frame_index.change(update_frame, inputs=[frames, frame_index], outputs=[frame_output])\n",
    "        frame_output.change(get_faces_in_frame, inputs=[face_resolver, frame_output], outputs=[face_gallery])\n",
    "        face_gallery.select(lambda x: x, inputs=[face_index], outputs=[face_index])\n",
    "        preview_button.click(generate_preview, inputs=[face_resolver, face_index, similarity_strength], outputs=[preview_video])\n",
    "        save_button.click(save_data, inputs=[face_resolver], outputs=[save_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "import os\n",
    "\n",
    "from sympy import preview\n",
    "\n",
    "# Assuming helpers.file_check as fc is correctly configured\n",
    "import helpers.file_check as fc\n",
    "\n",
    "class FaceResolver:\n",
    "    def __init__(self, video_path):\n",
    "        self.video_path = video_path\n",
    "        self.face_detector = FaceAnalysis(providers=['CUDAExecutionProvider'])\n",
    "        self.face_detector.prepare(ctx_id=0, det_size=(640, 640))\n",
    "        \n",
    "        self.selected_embedding = 0\n",
    "        self.faces = []\n",
    "\n",
    "        self.presence_mask = []\n",
    "        self.bboxes = []\n",
    "        self.kps = []\n",
    "\n",
    "    def get_faces(self, frame):\n",
    "        faces = self.face_detector.get(frame)\n",
    "        self.faces = faces\n",
    "    \n",
    "    def get_embedding(self, index, faces):\n",
    "        self.selected_embedding = faces[index].normed_embedding\n",
    "\n",
    "    def _compare_embeddings(self, emb1, emb2, strength = 1.2):\n",
    "        return np.linalg.norm(emb1 - emb2) < strength\n",
    "\n",
    "    def get_preview(self, similarity_strength):\n",
    "        bboxes = []\n",
    "        presence_mask = []\n",
    "        keypoints = []\n",
    "\n",
    "        video = cv2.VideoCapture(self.video_path)\n",
    "\n",
    "        # Metadata\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Writer Object for output video\n",
    "        preview_path = os.path.join(fc.MEDIA_DIR, 'preview.mp4')\n",
    "        writer = cv2.VideoWriter(preview_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "        # Loop through the video\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            faces = self.face_detector.get(frame)\n",
    "            if faces:\n",
    "                present = False\n",
    "                for face in faces:\n",
    "                    bbox = face.bbox.astype(int)\n",
    "                    landmark = face.kps.astype(int)\n",
    "                    embedding = face.normed_embedding\n",
    "                    if self._compare_embeddings(embedding, self.selected_embedding, similarity_strength):\n",
    "                        bboxes.append(bbox)\n",
    "                        keypoints.append(landmark)\n",
    "                        present = True\n",
    "\n",
    "                        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "                        for i in range(5):\n",
    "                            cv2.circle(frame, (landmark[i][0], landmark[i][1]), 1, (0, 0, 255), 2)\n",
    "                presence_mask.append(present)\n",
    "            else:\n",
    "                presence_mask.append(False)\n",
    "            \n",
    "            writer.write(frame)\n",
    "        \n",
    "        self.presence_mask = np.asarray(presence_mask, dtype=bool)\n",
    "        self.bboxes = np.asarray(bboxes)\n",
    "        self.kps = np.asarray(keypoints)\n",
    "        \n",
    "        video.release()\n",
    "        writer.release()\n",
    "        \n",
    "        return preview_path\n",
    "\n",
    "    def save_state(self):\n",
    "        np.save(os.path.join(fc.NPY_FILES_DIR, 'presence_mask.npy'), self.presence_mask)\n",
    "        np.save(os.path.join(fc.NPY_FILES_DIR, 'bboxes.npy'), self.bboxes)\n",
    "        np.save(os.path.join(fc.NPY_FILES_DIR, 'keypoints.npy'), self.kps)\n",
    "        \n",
    "def process_video(video_file):\n",
    "    video_capture = cv2.VideoCapture(video_file.name)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    video_capture.release()\n",
    "    return frames\n",
    "\n",
    "def update_frame(frames, frame_index):\n",
    "    if frame_index < len(frames):\n",
    "        return frames[frame_index]\n",
    "    return None\n",
    "\n",
    "def get_faces_in_frame(face_resolver, frame):\n",
    "    face_resolver.get_faces(frame)\n",
    "    faces = face_resolver.faces\n",
    "    face_images = []\n",
    "    for face in faces:\n",
    "        bbox = face.bbox.astype(int)\n",
    "        face_image = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        face_images.append(face_image)\n",
    "    return face_images\n",
    "\n",
    "def generate_preview(face_resolver, face_index: gr.SelectData, similarity_strength):\n",
    "    face_resolver.get_embedding(face_index.index, face_resolver.faces)\n",
    "    preview_path = face_resolver.get_preview(similarity_strength)\n",
    "    return preview_path\n",
    "\n",
    "def save_data(face_resolver):\n",
    "    face_resolver.save_state()\n",
    "    return \"Data saved successfully!\"\n",
    "\n",
    "def main():\n",
    "    fc.perform_check()\n",
    "    with gr.Blocks() as demo:\n",
    "        video_file = gr.File(label=\"Upload Video\")\n",
    "        frames = gr.State([])\n",
    "        frame_index = gr.Slider(minimum=0, maximum=1, step=1, label=\"Frame Index\", interactive=True)\n",
    "        frame_output = gr.Image(label=\"Frame Preview\")\n",
    "        face_gallery = gr.Gallery(label=\"Faces in Frame\")\n",
    "        face_index = gr.Number(label=\"Selected Face Index\", value=0)\n",
    "        similarity_strength = gr.Slider(minimum=0.1, maximum=2.0, step=0.1, value=1.2, label=\"Similarity Strength\")\n",
    "        preview_video = gr.Video(label=\"Preview Video\")\n",
    "        preview_button = gr.Button(\"Generate Preview\")\n",
    "        save_button = gr.Button(\"Save Data\")\n",
    "        save_output = gr.Textbox(label=\"Save Status\")\n",
    "\n",
    "        face_resolver = gr.State(None)\n",
    "\n",
    "        def load_video(video_file):\n",
    "            frames_list = process_video(video_file)\n",
    "            frame_index_update = gr.update(maximum=len(frames_list) - 1) if frames_list else gr.update(maximum=0)\n",
    "            return frames_list, FaceResolver(video_file.name), frame_index_update\n",
    "\n",
    "        video_file.change(load_video, inputs=[video_file], outputs=[frames, face_resolver, frame_index])\n",
    "        frame_index.change(update_frame, inputs=[frames, frame_index], outputs=[frame_output])\n",
    "        frame_output.change(get_faces_in_frame, inputs=[face_resolver, frame_output], outputs=[face_gallery])\n",
    "        face_gallery.select(lambda x: x, inputs=[face_index], outputs=[face_index])\n",
    "        preview_button.click(generate_preview, inputs=[face_resolver, face_index, similarity_strength], outputs=[preview_video])\n",
    "        save_button.click(save_data, inputs=[face_resolver], outputs=[save_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Sample image URLs\n",
    "images = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/3Stars-Micronation_Flag.svg/1200px-3Stars-Micronation_Flag.svg.png\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Circle_-_black_simple.svg/1200px-Circle_-_black_simple.svg.png\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/Solid_white.svg/2048px-Solid_white.svg.png\"\n",
    "]\n",
    "\n",
    "def select_image(image, evt: gr.SelectData):\n",
    "    index = evt.index\n",
    "    return f\"Selected image index: {index}\", image\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gallery = gr.Gallery(images, label=\"Select an image\")\n",
    "    output = gr.Textbox(label=\"Image Index\")\n",
    "    out_img = gr.Textbox(label=\"Selected Image\")\n",
    "\n",
    "    gallery.select(select_image, gallery, [output,out_img])\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lipwise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
